setup: 'squad_split_v1'

#########################################################################################################
# ---------------------------------------- DATA CONFIGURATIONS ---------------------------------------- #
#########################################################################################################

cached_train_path: 'data/squad_split_v1/train.pt'
cached_dev_path: 'data/squad_split_v1/dev.pt'
cached_test_path: 'data/squad_split_v1/test.pt'
cached_vocabularies_path: 'data/squad_split_v1/vocab.pt'

vocab_size: 45000

min_word_frequency: 1

max_source_length: 200
max_target_length: 50


##########################################################################################################
# ---------------------------------------- MODEL CONFIGURATIONS ---------------------------------------- #
##########################################################################################################

embedding_size: 300
hidden_size: 512
num_layers: 2
dropout: 0.3

use_pointer: True

# Initialization
param_init: 0.1
param_init_glorot: True


#########################################################################################################
# -------------------------------------- TRAINING CONFIGURATIONS -------------------------------------- #
#########################################################################################################

cached_model_dir: checkpoints

num_train_epochs: 10
#num_train_steps: 25000
#num_valid_steps: 500

batch_size: 64

optimizer_name: adam
sgd_learning_rate: 0.1
adam_learning_rate: 0.00025

max_grad_norm: 5.

max_to_keep: 10


#########################################################################################################
# ------------------------------------- INFERENCE CONFIGURATIONS ------------------------------------- #
#########################################################################################################

beam_size: 10
min_decode_step: 8
max_decode_step: 30

output: generated_question.txt